<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en" >
  <!-- The Head -->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="【DAILY READING】Augmented Language Models：a Survey" />
<meta property="og:locale" content="en" />
<meta name="description" content="Conclusion By Myself Table of Contents Abstract This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues. 1 Introduction: motivation for the survey and definitions 1.1 Motivation more reading [ ] Evaluating large language models trained on code copilot [ ] Neural text generation with unlikelihood training. In International Conference on Learning Representations hallucinations fundamental defect of today’s LLMs a single parametric model a limited context external things can integrate into LLMs external documents external data sources external tools definitions in this survey Reasoning: reasoning is decomposing a potentially complex task into simpler subtasks the LM can solve more easily by itself or using tools. Tool: a tool is an external module that is typically called using a rule or a special token and whose output is included in the ALM’s context. Act: we will sometimes denote the call of a tool by an ALM as an action, even if it does not have an external effect." />
<meta property="og:description" content="Conclusion By Myself Table of Contents Abstract This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues. 1 Introduction: motivation for the survey and definitions 1.1 Motivation more reading [ ] Evaluating large language models trained on code copilot [ ] Neural text generation with unlikelihood training. In International Conference on Learning Representations hallucinations fundamental defect of today’s LLMs a single parametric model a limited context external things can integrate into LLMs external documents external data sources external tools definitions in this survey Reasoning: reasoning is decomposing a potentially complex task into simpler subtasks the LM can solve more easily by itself or using tools. Tool: a tool is an external module that is typically called using a rule or a special token and whose output is included in the ALM’s context. Act: we will sometimes denote the call of a tool by an ALM as an action, even if it does not have an external effect." />
<link rel="canonical" href="http://localhost:4000/posts/Augmented-Language-Models-a-Survey/" />
<meta property="og:url" content="http://localhost:4000/posts/Augmented-Language-Models-a-Survey/" />
<meta property="og:site_name" content="washing" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-10-29T20:15:39+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="【DAILY READING】Augmented Language Models：a Survey" />
<meta name="twitter:site" content="@washing77231482" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-10-29T20:47:44+08:00","datePublished":"2023-10-29T20:15:39+08:00","description":"Conclusion By Myself Table of Contents Abstract This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues. 1 Introduction: motivation for the survey and definitions 1.1 Motivation more reading [ ] Evaluating large language models trained on code copilot [ ] Neural text generation with unlikelihood training. In International Conference on Learning Representations hallucinations fundamental defect of today’s LLMs a single parametric model a limited context external things can integrate into LLMs external documents external data sources external tools definitions in this survey Reasoning: reasoning is decomposing a potentially complex task into simpler subtasks the LM can solve more easily by itself or using tools. Tool: a tool is an external module that is typically called using a rule or a special token and whose output is included in the ALM’s context. Act: we will sometimes denote the call of a tool by an ALM as an action, even if it does not have an external effect.","headline":"【DAILY READING】Augmented Language Models：a Survey","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/Augmented-Language-Models-a-Survey/"},"url":"http://localhost:4000/posts/Augmented-Language-Models-a-Survey/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>【DAILY READING】Augmented Language Models：a Survey | washing
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="washing">
<meta name="application-name" content="washing">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.2/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.21.2/dist/tocbot.min.css">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  
    <!-- Switch the mode between dark and light. -->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() {
      return 'mode';
    }
    static get MODE_ATTR() {
      return 'data-mode';
    }
    static get DARK_MODE() {
      return 'dark';
    }
    static get LIGHT_MODE() {
      return 'light';
    }
    static get ID() {
      return 'mode-toggle';
    }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener('change', () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }
          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();
      });
    } /* constructor() */

    get sysDarkPrefers() {
      return window.matchMedia('(prefers-color-scheme: dark)');
    }

    get isSysDarkPrefer() {
      return this.sysDarkPrefers.matches;
    }

    get isDarkMode() {
      return this.mode === ModeToggle.DARK_MODE;
    }

    get isLightMode() {
      return this.mode === ModeToggle.LIGHT_MODE;
    }

    get hasMode() {
      return this.mode != null;
    }

    get mode() {
      return sessionStorage.getItem(ModeToggle.MODE_KEY);
    }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      document.documentElement.removeAttribute(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage(
        {
          direction: ModeToggle.ID,
          message: this.modeStatus
        },
        '*'
      );
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }
        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }
      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.notify();
    } /* flipMode() */
  } /* ModeToggle */

  const modeToggle = new ModeToggle();
</script>

  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end">
  <header class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle">
      
        
        <img src="/assets/img/avatar/dragonball.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'">
      
    </a>

    <h1 class="site-title">
      <a href="/">washing</a>
    </h1>
    <p class="site-subtitle fst-italic mb-0">The journey is long and arduous, my heart is calm and resolute.</p>
  </header>
  <!-- .profile-wrapper -->

  <nav class="flex-column flex-grow-1 w-100 ps-0">
    <ul class="nav">
      <!-- home -->
      <li class="nav-item">
        <a href="/" class="nav-link">
          <i class="fa-fw fas fa-home"></i>
          <span>HOME</span>
        </a>
      </li>
      <!-- the real tabs -->
      
        <li class="nav-item">
          <a href="/categories/" class="nav-link">
            <i class="fa-fw fas fa-stream"></i>
            

            <span>CATEGORIES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/tags/" class="nav-link">
            <i class="fa-fw fas fa-tags"></i>
            

            <span>TAGS</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/archives/" class="nav-link">
            <i class="fa-fw fas fa-archive"></i>
            

            <span>ARCHIVES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/about/" class="nav-link">
            <i class="fa-fw fas fa-info-circle"></i>
            

            <span>ABOUT</span>
          </a>
        </li>
        <!-- .nav-item -->
      
    </ul>
  </nav>

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    
      <button type="button" class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
        <a
          href="https://github.com/washing1127"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="https://twitter.com/washing77231482"
          aria-label="twitter"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fa-brands fa-x-twitter"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['washing1127','gmail.com'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="/feed.xml"
          aria-label="rss"
          

          

          

          
        >
          <i class="fas fa-rss"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</aside>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div class="container d-flex flex-column px-xxl-5">
        <!-- The Top Bar -->

<header id="topbar-wrapper" aria-label="Top Bar">
  <div
    id="topbar"
    class="d-flex align-items-center justify-content-between px-lg-3 h-100"
  >
    <nav id="breadcrumb" aria-label="Breadcrumb">
      

      
        
          
            <span>
              <a href="/">
                Home
              </a>
            </span>

          
        
          
        
          
            
              <span>【DAILY READING】Augmented Language Models：a Survey</span>
            

          
        
      
    </nav>
    <!-- endof #breadcrumb -->

    <button type="button" id="sidebar-trigger" class="btn btn-link">
      <i class="fas fa-bars fa-fw"></i>
    </button>

    <div id="topbar-title">
      Post
    </div>

    <button type="button" id="search-trigger" class="btn btn-link">
      <i class="fas fa-search fa-fw"></i>
    </button>

    <search class="align-items-center ms-3 ms-lg-0">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="Search..."
      >
    </search>
    <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button>
  </div>
</header>


        <div class="row flex-grow-1">
          <main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->



<!-- Handle images -->





<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  




<!-- return -->




<article class="px-1">
  <header>
    <h1 data-toc-skip>【DAILY READING】Augmented Language Models：a Survey</h1>

    <div class="post-meta text-muted">
      <!-- published date -->
      <span>
        Posted
        <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1698581739"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Oct 29, 2023
</time>

      </span>

      <!-- lastmod date -->
      
        <span>
          Updated
          <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1698583664"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Oct 29, 2023
</time>

        </span>
      

      

      <div class="d-flex justify-content-between">
        <!-- author(s) -->
        <span>
          

          By

          <em>
            
              <a href="https://www.cnblogs.com/washing/">washing</a>
            
          </em>
        </span>

        <!-- read time -->
        <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="875 words"
>
  <em>4 min</em> read</span>

      </div>
      <!-- .d-flex -->
    </div>
    <!-- .post-meta -->
  </header>

  <div class="content">
    <h1 id="conclusion-by-myself">Conclusion By Myself</h1>
<h1 id="table-of-contents">Table of Contents</h1>
<h2 id="abstract"><span class="me-2">Abstract</span><a href="#abstract" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<p>This survey reviews works in which language models (LMs) are augmented with <strong>reasoning skills</strong> and the <strong>ability to use tools</strong>.
The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter.
LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. 
While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. 
We therefore refer to them as <em>Augmented Language Models (ALMs)</em>. 
The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. 
In this work, after reviewing current advance in ALMs, we conclude that <em>this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues</em>.</p>
<h2 id="1-introduction-motivation-for-the-survey-and-definitions"><span class="me-2">1 Introduction: motivation for the survey and definitions</span><a href="#1-introduction-motivation-for-the-survey-and-definitions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="11-motivation"><span class="me-2">1.1 Motivation</span><a href="#11-motivation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>more reading
    <ul>
      <li>
        <div class="table-wrapper"><table>
          <tbody>
            <tr>
              <td>[ ] Evaluating large language models trained on code</td>
              <td>copilot</td>
            </tr>
          </tbody>
        </table></div>
      </li>
      <li>
        <div class="table-wrapper"><table>
          <tbody>
            <tr>
              <td>[ ] Neural text generation with unlikelihood training. In International Conference on Learning Representations</td>
              <td>hallucinations</td>
            </tr>
          </tbody>
        </table></div>
      </li>
    </ul>
  </li>
  <li>fundamental defect of today’s LLMs
    <ol>
      <li>a single parametric model</li>
      <li>a limited context</li>
    </ol>
  </li>
  <li>external things can integrate into LLMs
    <ol>
      <li>external documents</li>
      <li>external data sources</li>
      <li>external tools</li>
    </ol>
  </li>
  <li>definitions in this survey
    <ul>
      <li>Reasoning: reasoning is decomposing a potentially complex task into simpler subtasks the LM can solve more easily by itself or using tools.</li>
      <li>Tool: a tool is an external module that is typically called using a rule or a special token and whose output is included in the ALM’s context.</li>
      <li>Act: we will sometimes denote the call of a tool by an ALM as an action, even if it does not have an external effect.</li>
    </ul>
  </li>
</ul>

<h4 id="why-jointly-discussing-reasoning-and-tools"><span class="me-2">Why jointly discussing reasoning and tools</span><a href="#why-jointly-discussing-reasoning-and-tools" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<h4 id="why-jointly-discussing-tools-and-actions"><span class="me-2">Why jointly discussing tools and actions</span><a href="#why-jointly-discussing-tools-and-actions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<h3 id="12-our-classification"><span class="me-2">1.2 Our classification</span><a href="#12-our-classification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<h2 id="2-reasoning"><span class="me-2">2 Reasoning</span><a href="#2-reasoning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="21-eliciting-reasoning-with-prompting"><span class="me-2">2.1 Eliciting reasoning with prompting</span><a href="#21-eliciting-reasoning-with-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>elicitive prompts encourage LMs to solve tasks by following intermediate steps before predicting the output/answer.</p>
<h4 id="few-shot-setting"><span class="me-2">Few-shot setting</span><a href="#few-shot-setting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<ul class="task-list">
  <li>
    <div class="table-wrapper"><table>
      <tbody>
        <tr>
          <td>[ ] Chain of thought prompting elicits reasoning in large language models.</td>
          <td>Chain-of-Thought</td>
        </tr>
      </tbody>
    </table></div>
  </li>
  <li>
    <div class="table-wrapper"><table>
      <tbody>
        <tr>
          <td>[ ] Measuring and narrowing the compositionality gap in language models</td>
          <td>self-ask</td>
        </tr>
      </tbody>
    </table></div>
  </li>
  <li class="task-list-item"><i class="far fa-circle fa-fw"></i>Webshop: Towards scalable real-world web interaction with grounded language agents. | ReAct
    <h4 id="zero-shot-setting"><span class="me-2">Zero-shot setting</span><a href="#zero-shot-setting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <p>few-shot provides examples of the task at hand, zero-shot conditions the LM on a single prompt that is not an example.</p>
  </li>
  <li class="task-list-item"><i class="far fa-circle fa-fw"></i>Large language models are zero-shot reasoners. | think step by step
    <h3 id="22-recursive-prompting"><span class="me-2">2.2 Recursive prompting</span><a href="#22-recursive-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
    <h3 id="23-explicitly-teaching-language-models-to-reason"><span class="me-2">2.3 Explicitly teaching language models to reason</span><a href="#23-explicitly-teaching-language-models-to-reason" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
    <p>all works also show that small scale instruction-finetuned models can perform better than un-finetuned large scale models, especially in the tasks where instruction following is important</p>
    <h3 id="24-comparison-and-limitations-of-abstract-reasoning"><span class="me-2">2.4 Comparison and limitations of abstract reasoning</span><a href="#24-comparison-and-limitations-of-abstract-reasoning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
    <p>overall, reasoning can be seen as decomposing a problem into a sequence of sub-problems either iteratively or recursively.</p>
  </li>
  <li class="task-list-item"><i class="far fa-circle fa-fw"></i>Hypertree proof search for neural theorem proving. | example of other reasoning structures such as trees could be considered
    <h2 id="3-using-tools-and-act"><span class="me-2">3 Using Tools and Act</span><a href="#3-using-tools-and-act" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
    <p>The possibility to easily include tools and actions in the form of special tokens is a convenient feature of language modeling coupled with transformers.</p>
    <h3 id="31-calling-another-model"><span class="me-2">3.1 Calling another model</span><a href="#31-calling-another-model" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
    <h4 id="iterative-lm-calling"><span class="me-2">Iterative LM calling</span><a href="#iterative-lm-calling" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
  </li>
  <li>
    <div class="table-wrapper"><table>
      <tbody>
        <tr>
          <td>[ ] Re3: Generating longer stories with recursive reprompting and revision.</td>
          <td>seems interesting</td>
        </tr>
      </tbody>
    </table></div>
  </li>
  <li>
    <div class="table-wrapper"><table>
      <tbody>
        <tr>
          <td>[ ] Diffusion-lm improves controllable text generation.</td>
          <td>a model can denoising sequence of Gaussian vectors into word vectors</td>
        </tr>
      </tbody>
    </table></div>
  </li>
  <li class="task-list-item"><i class="far fa-circle fa-fw"></i>Peer: A collaborative language model. | a model can call itself repeatedly
    <h4 id="leveraging-other-modalities"><span class="me-2">Leveraging other modalities</span><a href="#leveraging-other-modalities" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
  </li>
  <li class="task-list-item"><i class="far fa-circle fa-fw"></i>Flamingo: a visual language model for few-shot learning.</li>
  <li class="task-list-item"><i class="far fa-circle fa-fw"></i>Socratic models: Composing zero-shot multimodal reasoning with language | a modular framework allows models exchange information with each other and acquire new multimodal capabilities without additional finetuning
    <h3 id="32-information-retrieval"><span class="me-2">3.2 Information retrieval</span><a href="#32-information-retrieval" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
    <h4 id="321-retrieval-augmented-language-models"><span class="me-2">3.2.1 Retrieval-augmented language models</span><a href="#321-retrieval-augmented-language-models" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <h5 id="dense-and-sparse-retrievers"><span class="me-2">Dense and sparse retrievers</span><a href="#dense-and-sparse-retrievers" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5>
    <p>both types of retrievers assess the relevance of a document to an information-seeking query. this can be done by:</p>
    <ol>
      <li>checking for precise term overlap, or</li>
      <li>computing the semantic similarity across related concepts.
        <h5 id="conditioning-lms-on-retrieved-documents"><span class="me-2">Conditioning LMs on retrieved documents</span><a href="#conditioning-lms-on-retrieved-documents" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5>
        <h5 id="chain-of-thought-prompting-and-retrievers"><span class="me-2">Chain-of-thought prompting and retrievers</span><a href="#chain-of-thought-prompting-and-retrievers" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5>
        <h4 id="322-querying-search-engines"><span class="me-2">3.2.2 Querying search engines</span><a href="#322-querying-search-engines" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
        <p>In general, reasoning can improve decision making by making better inferences and predictions, while the ability to use external tools can improve reasoning by gathering additional information from knowledge bases or environments</p>
        <h4 id="323-searching-and-navigating-the-web"><span class="me-2">3.2.3 Searching and navigating the web</span><a href="#323-searching-and-navigating-the-web" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
      </li>
    </ol>
  </li>
  <li class="task-list-item"><i class="far fa-circle fa-fw"></i>Webgpt: Browser-assisted question-answering with human feedback. | a LM-based agent, can search the internet, navigate webpages, follow links, and cite sources
    <h3 id="33-computing-via-symbolic-modules-and-code-interpreters"><span class="me-2">3.3 Computing via Symbolic Modules and Code Interpreters</span><a href="#33-computing-via-symbolic-modules-and-code-interpreters" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
    <h3 id="34-acting-on-the-virtual-and-physical-world"><span class="me-2">3.4 Acting on the virtual and physical world</span><a href="#34-acting-on-the-virtual-and-physical-world" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
    <h4 id="controlling-virtual-agents"><span class="me-2">Controlling Virtual Agents</span><a href="#controlling-virtual-agents" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <h4 id="controlling-physical-robots"><span class="me-2">Controlling Physical Robots</span><a href="#controlling-physical-robots" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <h2 id="4-learning-to-reason-use-tools-and-act"><span class="me-2">4 Learning to reason, use tools, and act</span><a href="#4-learning-to-reason-use-tools-and-act" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
    <h3 id="41-supervision"><span class="me-2">4.1 Supervision</span><a href="#41-supervision" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
    <h4 id="few-shot-prompting"><span class="me-2">Few-shot prompting</span><a href="#few-shot-prompting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <h4 id="fine-tuning"><span class="me-2">Fine-tuning</span><a href="#fine-tuning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <h4 id="prompt-pre-training"><span class="me-2">Prompt pre-training</span><a href="#prompt-pre-training" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <h4 id="bootstrapping"><span class="me-2">Bootstrapping</span><a href="#bootstrapping" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <h3 id="42-reinforcement-learning"><span class="me-2">4.2 Reinforcement learning</span><a href="#42-reinforcement-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
    <h4 id="hard-coded-reward-functions"><span class="me-2">Hard-coded reward functions</span><a href="#hard-coded-reward-functions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <h4 id="human-feedback"><span class="me-2">Human feedback</span><a href="#human-feedback" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
  </li>
  <li class="task-list-item">RLHFs:
    <ul class="task-list">
      <li class="task-list-item"><i class="far fa-circle fa-fw"></i>Tamer: Training an agent manually via evaluative reinforcement.</li>
      <li class="task-list-item"><i class="far fa-circle fa-fw"></i>Interactive learning from policy-dependent human feedback.</li>
      <li class="task-list-item"><i class="far fa-circle fa-fw"></i>Deep reinforcement learning from human preferences.</li>
      <li class="task-list-item"><i class="far fa-circle fa-fw"></i>Deep tamer: Interactive agent shaping in high-dimensional state spaces.
        <h3 id="43-limitations-and-future-directions"><span class="me-2">4.3 Limitations and future directions</span><a href="#43-limitations-and-future-directions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
        <h2 id="5-discussion"><span class="me-2">5 Discussion</span><a href="#5-discussion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
        <h3 id="moving-away-from-language-modeling"><span class="me-2">Moving away from language modeling</span><a href="#moving-away-from-language-modeling" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
        <h3 id="a-tradeoff-between-memorizing-and-querying-tools"><span class="me-2">A tradeoff between memorizing and querying tools</span><a href="#a-tradeoff-between-memorizing-and-querying-tools" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
        <h3 id="generalizing-the-non-parametric-framework"><span class="me-2">Generalizing the non-parametric framework</span><a href="#generalizing-the-non-parametric-framework" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
        <h3 id="a-path-towards-autonomous-machine-intelligence"><span class="me-2">A path towards autonomous machine intelligence</span><a href="#a-path-towards-autonomous-machine-intelligence" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
      </li>
    </ul>
  </li>
  <li class="task-list-item"><i class="far fa-circle fa-fw"></i>A path towards autonomous machine intelligence | LeCnn’s
    <h3 id="augmented-language-models-benefits"><span class="me-2">Augmented Language Models benefits</span><a href="#augmented-language-models-benefits" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
    <h4 id="truthfulness"><span class="me-2">Truthfulness</span><a href="#truthfulness" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <h4 id="estimating-and-reducing-uncertainty"><span class="me-2">Estimating and reducing uncertainty</span><a href="#estimating-and-reducing-uncertainty" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <h4 id="interpretability"><span class="me-2">Interpretability</span><a href="#interpretability" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <h4 id="enhanced-capabilities"><span class="me-2">Enhanced capabilities</span><a href="#enhanced-capabilities" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
    <h3 id="ethical-concerns"><span class="me-2">Ethical concerns</span><a href="#ethical-concerns" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
    <h1 id="file">File</h1>
    <p><a href="https://arxiv.org/abs/2302.07842">[2302.07842] Augmented Language Models: a Survey (arxiv.org)</a></p>
  </li>
</ul>

  </div>

  <div class="post-tail-wrapper text-muted">
    <!-- categories -->
    
      <div class="post-meta mb-3">
        <i class="far fa-folder-open fa-fw me-1"></i>
        
          <a href="/categories/paper/">paper</a>
      </div>
    

    <!-- tags -->
    
      <div class="post-tags">
        <i class="fa fa-tags fa-fw me-1"></i>
        
          <a
            href="/tags/daily-reading/"
            class="post-tag no-text-decoration"
          >daily reading</a>
        
      </div>
    

    <div
      class="
        post-tail-bottom
        d-flex justify-content-between align-items-center mt-5 pb-2
      "
    >
      <div class="license-wrapper">
        
          

          This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.
        
      </div>

      <!-- Post sharing snippet -->

<div class="share-wrapper d-flex align-items-center">
  <span class="share-label text-muted me-1">Share</span>
  <span class="share-icons">
    
    
    

    
      
      <a
        href="https://twitter.com/intent/tweet?text=%E3%80%90DAILY%20READING%E3%80%91Augmented%20Language%20Models%EF%BC%9Aa%20Survey%20-%20washing&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FAugmented-Language-Models-a-Survey%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Twitter"
        target="_blank"
        rel="noopener"
        aria-label="Twitter"
      >
        <i class="fa-fw fa-brands fa-square-x-twitter"></i>
      </a>
    
      
      <a
        href="https://www.facebook.com/sharer/sharer.php?title=%E3%80%90DAILY%20READING%E3%80%91Augmented%20Language%20Models%EF%BC%9Aa%20Survey%20-%20washing&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FAugmented-Language-Models-a-Survey%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Facebook"
        target="_blank"
        rel="noopener"
        aria-label="Facebook"
      >
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    
      
      <a
        href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FAugmented-Language-Models-a-Survey%2F&text=%E3%80%90DAILY%20READING%E3%80%91Augmented%20Language%20Models%EF%BC%9Aa%20Survey%20-%20washing"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Telegram"
        target="_blank"
        rel="noopener"
        aria-label="Telegram"
      >
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <button
      id="copy-link"
      aria-label="Copy link"
      class="btn small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="Copy link"
      data-title-succeed="Link copied successfully!"
    >
      <i class="fa-fw fas fa-link pe-none"></i>
    </button>
  </span>
</div>

    </div>
    <!-- .post-tail-bottom -->
  </div>
  <!-- div.post-tail-wrapper -->
</article>


            
          </main>

          <!-- panel -->
          <aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 mb-5 text-muted">
            <div class="access">
              <!-- Get the last 5 posts from lastmod list. -->














  <section id="access-lastmod">
    <h2 class="panel-heading">Recently Updated</h2>
    <ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Distilling-the-Knowledge-in-a-Neural-Network/">【DAILY READING】Distilling the Knowledge in a Neural Network</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/DistilBERT,-a-distilled-version-of-BERT-smaller,-faster,-cheaper-and-lighter/">【DAILY READING】DistilBERT, a distilled version of BERT：smaller, faster, cheaper and lighter</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/iTransformer-Inverted-Transformer-Are-Effective-for-Time-Series-Forecasting/">【DAILY READING】iTransformer：Inverted Transformer Are Effective for Time Series Forecasting</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Deep-contextualized-word-realizations/">【DAILY READING】Deep contextualized word realizations</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Efficient-Estimation-of-Word-Representations-in-Vector-Space/">【DAILY READING】Efficient Estimation of Word Representations in Vector Space</a>
        </li>
      
    </ul>
  </section>
  <!-- #access-lastmod -->


              <!-- The trending tags list -->















  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/daily-reading/">daily reading</a>
      
    </div>
  </section>


            </div>

            
              
              



  <section id="toc-wrapper" class="ps-0 pe-4">
    <h2 class="panel-heading ps-3 pt-2 mb-2">Contents</h2>
    <nav id="toc"></nav>
  </section>


            
          </aside>
        </div>

        <div class="row">
          <!-- tail -->
          <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              
              <!-- Recommend the other 3 posts according to the tags and categories of the current post. -->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->














  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  











  <aside id="related-posts" aria-labelledby="related-label">
    <h3 class="mb-4" id="related-label">Further Reading</h3>
    <nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        <article class="col">
          <a href="/posts/Distilling-the-Knowledge-in-a-Neural-Network/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1698581701"
  data-df="ll"
  
>
  Oct 29, 2023
</time>

              <h4 class="pt-0 my-2">【DAILY READING】Distilling the Knowledge in a Neural Network</h4>
              <div class="text-muted">
                <p>
                  





                  Conclusion By Myself
This paper introduced that it is helpful to train a little model with a big model. 
The specific method is train a big model with a lot of data and make it performance good. Th...
                </p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/DistilBERT,-a-distilled-version-of-BERT-smaller,-faster,-cheaper-and-lighter/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1698581711"
  data-df="ll"
  
>
  Oct 29, 2023
</time>

              <h4 class="pt-0 my-2">【DAILY READING】DistilBERT, a distilled version of BERT：smaller, faster, cheaper and lighter</h4>
              <div class="text-muted">
                <p>
                  





                  Conclusion By Myself
This paper is about distilling BERT model. It is not so hard to read, but because the lacking of the distilling knowledge, I still can not clearly know what it said, Aha.
It in...
                </p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/iTransformer-Inverted-Transformer-Are-Effective-for-Time-Series-Forecasting/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1698581717"
  data-df="ll"
  
>
  Oct 29, 2023
</time>

              <h4 class="pt-0 my-2">【DAILY READING】iTransformer：Inverted Transformer Are Effective for Time Series Forecasting</h4>
              <div class="text-muted">
                <p>
                  





                  Conclusion By Myself
Honestly, this paper is not so clear to me. So I came back to this article Transformer王者归来！ where introduced the paper to me.
This is a specific aspect of transformer on time s...
                </p>
              </div>
            </div>
          </a>
        </article>
      
    </nav>
  </aside>
  <!-- #related-posts -->


            
              
              <!-- Navigation buttons at the bottom of the post. -->

<nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation">
  
  

  
    <a
      href="/posts/Textbooks-Are-All-You-Need/"
      class="btn btn-outline-primary"
      aria-label="Older"
    >
      <p>【DAILY READING】Textbooks Are All You Need</p>
    </a>
  

  
    <a
      href="/posts/CodeChain-Towards-Modular-Code-Generation-Through-Chain-of-Self-revisions-with-Representative-Sub-modules/"
      class="btn btn-outline-primary"
      aria-label="Newer"
    >
      <p>【DAILY READING】CodeChain：Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules</p>
    </a>
  
</nav>

            
              
              <!--  The comments switcher -->


            

            <!-- The Footer -->

<footer
  aria-label="Site Info"
  class="
    d-flex flex-column justify-content-center text-muted
    flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3
  "
>
  <p>
    ©
    <time>2023</time>
    <a href="https://www.cnblogs.com/washing/">washing</a>.
    
      <span
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."
      >Some rights reserved.</span>
    
  </p>

  <p>Using the <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>
  </p>
</footer>

          </div>
        </div>

        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-11 content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/daily-reading/">daily reading</a>
      
    </div>
  </section>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>

      <aside aria-label="Scroll to Top">
        <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow">
          <i class="fas fa-angle-up"></i>
        </button>
      </aside>
    </div>

    <div id="mask"></div>

    
      <aside
  id="notification"
  class="toast"
  role="alert"
  aria-live="assertive"
  aria-atomic="true"
  data-bs-animation="true"
  data-bs-autohide="false"
>
  <div class="toast-header">
    <button
      type="button"
      class="btn-close ms-auto"
      data-bs-dismiss="toast"
      aria-label="Close"
    ></button>
  </div>
  <div class="toast-body text-center pt-0">
    <p class="px-2 mb-3">A new version of content is available.</p>
    <button type="button" class="btn btn-primary" aria-label="Update">
      Update
    </button>
  </div>
</aside>

    

    <!-- JavaScripts -->

    <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.1/dist/jquery.min.js,npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.10/dayjs.min.js,npm/dayjs@1.11.10/locale/en.min.js,npm/dayjs@1.11.10/plugin/relativeTime.min.js,npm/dayjs@1.11.10/plugin/localizedFormat.min.js,npm/tocbot@4.21.2/dist/tocbot.min.js"></script>






<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
    /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
    MathJax = {
      tex: {
        /* start/end delimiter pairs for in-line math */
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ],
        /* start/end delimiter pairs for display math */
        displayMath: [
          ['$$', '$$'],
          ['\\[', '\\]']
        ]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>





    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  /* Note: dependent library will be loaded in `js-selector.html` */
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('search-results'),
    json: '/assets/js/data/search.json',
    searchResultTemplate: '  <article class="px-1 px-sm-2 px-lg-4 px-xl-0">    <header>      <h2><a href="{url}">{title}</a></h2>      <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">        {categories}        {tags}      </div>    </header>    <p>{snippet}</p>  </article>',
    noResultsText: '<p class="mt-5"></p>',
    templateMiddleware: function(prop, value, template) {
      if (prop === 'categories') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
        }
      }

      if (prop === 'tags') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
        }
      }
    }
  });
</script>

  </body>
</html>

